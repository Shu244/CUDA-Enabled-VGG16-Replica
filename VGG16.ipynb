{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shu244/CUDA-Enabled-VGG16-Replica/blob/master/VGG16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRr5tIk6rMZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sets up environment variables to allow cudatoolkit and numba to function properly.\n",
        "import os\n",
        "os.environ['NUMBAPRO_LIBDEVICE'] = \"/usr/local/cuda-10.0/nvvm/libdevice\"\n",
        "os.environ['NUMBAPRO_NVVM'] = \"/usr/local/cuda-10.0/nvvm/lib64/libnvvm.so\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyRK7AOd6uKa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5224a669-b358-47b0-b117-ef198e9c9d1d"
      },
      "source": [
        "!git clone https://github.com/Shu244/CUDA-Enabled-VGG16-Replica.git\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'CUDA-Enabled-VGG16-Replica' already exists and is not an empty directory.\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oHdbqWCrRmV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from numba import cuda, vectorize\n",
        "import h5py\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def matrix_mul(matrix1, matrix2, result):\n",
        "    '''\n",
        "    Matrix 1 and 2 must be 2D arrays.\n",
        "    '''\n",
        "\n",
        "    thread_r, thread_c = cuda.grid(2)  # Gets position of thread.\n",
        "    thread_r_size, thread_c_size = cuda.gridsize(2)  # Gets total number of threads in each dimension.\n",
        "\n",
        "    result_r, result_c = result.shape\n",
        "\n",
        "    for thread_r_i in range(thread_r, result_r, thread_r_size):\n",
        "        for thread_c_i in range(thread_c, result_c, thread_c_size):\n",
        "            # The following code will calculate one element in the result matrix at location thread_r_i and thread_c_i.\n",
        "            for vector_i in range(0, matrix2.shape[0]):\n",
        "                result[thread_r_i, thread_c_i] = result[thread_r_i, thread_c_i] + matrix1[thread_r_i, vector_i] * matrix2[vector_i, thread_c_i]\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def same_convolve_multiple_filters(unpadded_input, kernal, result):\n",
        "    '''\n",
        "    Strides = 1.\n",
        "    unpadded_input and result must have the same shape.\n",
        "    Expected shape of the unpadded_input: channels, height, width\n",
        "    Expected shape of the kernal: kernals, channels, height, width.\n",
        "    Expected shape result: channels, height, width\n",
        "    '''\n",
        "    thread_channel, thread_r, thread_c = cuda.grid(3)  # Gets position of thread.\n",
        "    thread_channel_size, thread_r_size, thread_c_size = cuda.gridsize(\n",
        "        3)  # Gets total number of threads in each dimension.\n",
        "\n",
        "    kernal_channels, kernal_r, kernal_c = kernal.shape[1:]\n",
        "\n",
        "    # Padding that must be applied to all borders to maintain same dimension.\n",
        "    r_pad, c_pad = ((kernal_r - 1) // 2), ((kernal_c - 1) // 2)\n",
        "\n",
        "    result_channel, result_r, result_c = result.shape\n",
        "\n",
        "    for thread_channel_i in range(thread_channel, result_channel, thread_channel_size):\n",
        "        for thread_r_i in range(thread_r, result_r, thread_r_size):\n",
        "            for thread_c_i in range(thread_c, result_c, thread_c_size):\n",
        "                corner_input_r_i = thread_r_i - r_pad\n",
        "                corner_input_c_i = thread_c_i - c_pad\n",
        "                for kernal_channel_i in range(0, kernal_channels):\n",
        "                    for kernal_r_i in range(0, kernal_r):\n",
        "                        for kernal_c_i in range(0, kernal_c):\n",
        "                            input_r_i = corner_input_r_i + kernal_r_i\n",
        "                            input_c_i = corner_input_c_i + kernal_c_i\n",
        "                            if 0 <= input_r_i < result_r and 0 <= input_c_i < result_c:\n",
        "                                new_result = unpadded_input[kernal_channel_i, input_r_i, input_c_i] * kernal[thread_channel_i, kernal_channel_i, kernal_r_i, kernal_c_i]\n",
        "                                result[thread_channel_i, thread_r_i, thread_c_i] = result[thread_channel_i, thread_r_i, thread_c_i] + new_result\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def max_pooling_multiple_filters(input, window, result):\n",
        "    '''\n",
        "    Expectation: the dimensions of the input is disivible by dimensions of window. Further, windows do not overlap.\n",
        "    Expected shape of the input: channels, height, width\n",
        "    \"window\" is a tuple of format (height, width)\n",
        "    Expected shape of result: channels, height, width\n",
        "    '''\n",
        "    thread_channel, thread_r, thread_c = cuda.grid(3)  # Gets position of thread.\n",
        "    thread_channel_size, thread_r_size, thread_c_size = cuda.gridsize(3)  # Gets total number of threads in each dimension.\n",
        "\n",
        "    window_r, window_c = window\n",
        "\n",
        "    result_channel, result_r, result_c = result.shape\n",
        "\n",
        "    for thread_channel_i in range(thread_channel, result_channel, thread_channel_size):\n",
        "        for thread_r_i in range(thread_r, result_r, thread_r_size):\n",
        "            for thread_c_i in range(thread_c, result_c, thread_c_size):\n",
        "                input_r_corner_i = thread_r_i * window_r\n",
        "                input_c_corner_i = thread_c_i * window_c\n",
        "                max = input[thread_channel_i, input_r_corner_i, input_c_corner_i]\n",
        "                for window_r_i in range(0, window_r):\n",
        "                    for window_c_i in range(0, window_c):\n",
        "                        element = input[thread_channel_i, input_r_corner_i + window_r_i, input_c_corner_i + window_c_i]\n",
        "                        if element > max:\n",
        "                            max = element\n",
        "                result[thread_channel_i, thread_r_i, thread_c_i] = max\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def add_biases_2D(input, biases):\n",
        "    '''\n",
        "    Input is of format: height, width\n",
        "    There must be one bias per input element.\n",
        "    is one bias per layer.\n",
        "    '''\n",
        "    thread_r, thread_c = cuda.grid(2)  # Gets position of thread.\n",
        "    thread_r_size, thread_c_size = cuda.gridsize(2)  # Gets total number of threads in each dimension.\n",
        "\n",
        "    result_r, result_c = input.shape\n",
        "\n",
        "    for thread_r_i in range(thread_r, result_r, thread_r_size):\n",
        "        for thread_c_i in range(thread_c, result_c, thread_c_size):\n",
        "            input[thread_r_i, thread_c_i] = input[thread_r_i, thread_c_i] + biases[thread_r_i, thread_c_i]\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def add_biases_3D(input, biases):\n",
        "    '''\n",
        "    Input is of format: channels, height, width\n",
        "    The number of biases must be equal to the number of layers as there\n",
        "    is one bias per layer.\n",
        "    '''\n",
        "    thread_channel, thread_r, thread_c = cuda.grid(3)  # Gets position of thread.\n",
        "    thread_channel_size, thread_r_size, thread_c_size = cuda.gridsize(3)  # Gets total number of threads in each dimension.\n",
        "\n",
        "    result_channel, result_r, result_c = input.shape\n",
        "\n",
        "    for thread_channel_i in range(thread_channel, result_channel, thread_channel_size):\n",
        "        for thread_r_i in range(thread_r, result_r, thread_r_size):\n",
        "            for thread_c_i in range(thread_c, result_c, thread_c_size):\n",
        "                input[thread_channel_i, thread_r_i, thread_c_i] = input[thread_channel_i, thread_r_i, thread_c_i] + biases[thread_channel_i]\n",
        "\n",
        "\n",
        "# Using float64 because h5 file stores parameters in float64.\n",
        "@vectorize(['float32(float32)', 'float64(float64)'], target='cuda')\n",
        "def ReLU(activation):\n",
        "    if activation > 0:\n",
        "        return activation\n",
        "    return 0\n",
        "    ''' \n",
        "    return max(activation, 0) causes racing condition to occur. \n",
        "    '''\n",
        "\n",
        "\n",
        "def softmax(activations):\n",
        "    '''\n",
        "    Used only in last layer with 1000 neurons. Not worth the data transfer speed\n",
        "    to involve GPU.\n",
        "    '''\n",
        "    eactivations = np.exp(activations)\n",
        "    etotal = sum(eactivations)\n",
        "    return eactivations / etotal\n",
        "\n",
        "\n",
        "class VGG16:\n",
        "    def __init__(self, params_path, categories_path):\n",
        "        # reading in weights and baises now.\n",
        "        self.params = h5py.File(params_path, 'r')\n",
        "        self.input = None\n",
        "        self.categories = np.array([line.rstrip('\\n') for line in open(categories_path)])\n",
        "\n",
        "    def classify(self, image_path):\n",
        "        img = Image.open(image_path)\n",
        "        img = img.resize((224, 224), Image.ANTIALIAS)\n",
        "        # Flips image from RGB to BGR\n",
        "        img = np.flip(img, [2])\n",
        "        # Gets image to be in the format: channels, height, width\n",
        "        img = np.rollaxis(img, 2, 0)  \n",
        "        #print('Tranposed original image:\\n\\n',img[0,:5,:5])\n",
        "        # Put img array in C-contiguous format\n",
        "        img = img.copy(order='C')\n",
        "        img_device = cuda.to_device(img)\n",
        "        self.input = img_device\n",
        "\n",
        "        logits = self.forward_propagation()\n",
        "        return self.categorize(logits)\n",
        "\n",
        "    def categorize(self, logits, top_num=5):\n",
        "        guesses = []\n",
        "        for i in range(0, top_num):\n",
        "            index = np.argmax(logits)\n",
        "            output = (self.categories[index] + \" (prob: {0:.3f})\").format(logits[index])\n",
        "            guesses.append(output)\n",
        "            logits[index] = -1\n",
        "        return guesses\n",
        "\n",
        "    def forward_propagation(self):\n",
        "        layers_with_pool = (1, 3, 6, 9, 12)\n",
        "        threads_per_block = (4, 8, 16)\n",
        "        blocks_per_grid = (10, 10)\n",
        "        pool_window_height, pool_window_width = 2, 2\n",
        "        \n",
        "        #TEST\n",
        "        #orinput = self.input.copy_to_host()\n",
        "        #print('original image:\\n\\n',orinput[0,:5,:5])\n",
        "\n",
        "        # going through all convolution layers.\n",
        "        for i in range(0, 13):\n",
        "            filters = self.params[str(i)]['weights']    \n",
        "            biases = self.params[str(i)]['biases']\n",
        "            filters_device = cuda.to_device(filters)\n",
        "            biases_device = cuda.to_device(biases)\n",
        "\n",
        "            # Computes convolution.\n",
        "            result = np.zeros((filters.shape[0],) + self.input.shape[1:])\n",
        "            out_device = cuda.device_array_like(result)\n",
        "            same_convolve_multiple_filters[blocks_per_grid, threads_per_block](self.input, filters_device, out_device)\n",
        "\n",
        "            # Applying biases now.\n",
        "            add_biases_3D[blocks_per_grid, threads_per_block](out_device, biases_device)          \n",
        "\n",
        "            # Applying ReLU now.\n",
        "            out_device = ReLU(out_device)           \n",
        "            \n",
        "            # # Test print\n",
        "            # test = out_device.copy_to_host()\n",
        "            # print('weights:\\n\\n', filters[0,2,:,:])\n",
        "            # print(\"outputs: \\n\\n\", test[0, :10, :10])\n",
        "            # return\n",
        "\n",
        "            # Applying maxpool now, if necessary.\n",
        "            if i in layers_with_pool:\n",
        "                channels, height, width = out_device.shape\n",
        "                window_device = cuda.to_device((pool_window_height, pool_window_width))\n",
        "                new_out_device = cuda.device_array((channels, height // pool_window_height, width // pool_window_width))\n",
        "                max_pooling_multiple_filters[blocks_per_grid, threads_per_block](out_device, window_device, new_out_device)\n",
        "                out_device = new_out_device\n",
        "\n",
        "            self.input = out_device\n",
        "\n",
        "        # Must apply fully connected layers now.\n",
        "        threads_per_block = (32, 16)\n",
        "        blocks_per_grid = (10, 10)\n",
        "        # Converting volume to vector.\n",
        "        num_elements = np.prod(self.input.shape)\n",
        "        self.input = self.input.reshape((1, num_elements))\n",
        "        for i in range(13, 16):\n",
        "            # Setting up for CUDA Numba.\n",
        "            weights = self.params[str(i)]['weights']\n",
        "            biases = self.params[str(i)]['biases']\n",
        "            weights_device = cuda.to_device(weights)\n",
        "            biases_device = cuda.to_device(biases)\n",
        "\n",
        "            mult_result = np.zeros((self.input.shape[0], weights.shape[1]))\n",
        "            device_mult_result = cuda.to_device(mult_result)\n",
        "\n",
        "            # Performing matrix multiplication on GPU.\n",
        "            matrix_mul[blocks_per_grid, threads_per_block](self.input, weights_device, device_mult_result)\n",
        "\n",
        "            # Must add biases now.\n",
        "            biases_device = biases_device.reshape(device_mult_result.shape)\n",
        "            add_biases_2D(device_mult_result, biases_device)          \n",
        "\n",
        "            # Must apply ReLU now\n",
        "            self.input = ReLU(device_mult_result)\n",
        "\n",
        "        # Now applying softmax functon.\n",
        "        result = self.input.copy_to_host()\n",
        "        result = result.reshape(result.shape[1])\n",
        "        return softmax(result)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duJT6ySi0wRm",
        "colab_type": "code",
        "outputId": "06b17d4d-61fa-4c1a-98cb-2b8c58f6de06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        }
      },
      "source": [
        "image_paths = []\n",
        "\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/dog photo.jpg')\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/orangutan2.jpg')\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/orangutan3.jpg')\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/orangutan4.jpg')\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/orangutan5.jpg')\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/orangutan6.jpg')\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/magpie.jfif')\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/ostrich.jfif')\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/scorpion.jfif')\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/sea snake.jfif')\n",
        "image_paths.append('/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/tick.jfif')\n",
        "\n",
        "data_path = '/content/drive/My Drive/Colab Notebooks/VGG16 Test Data/vgg16_weights_reformatted.h5'\n",
        "categories_path = '/content/CUDA-Enabled-VGG16-Replica/Categories.txt'\n",
        "\n",
        "model = VGG16(data_path, categories_path)\n",
        "for paths in image_paths:\n",
        "    print(model.classify(paths))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['golden retriever (prob: 0.252)', 'Border collie (prob: 0.229)', 'collie (prob: 0.151)', 'tennis ball (prob: 0.095)', 'Shetland sheepdog, Shetland sheep dog, Shetland (prob: 0.048)']\n",
            "['orangutan, orang, orangutang, Pongo pygmaeus (prob: 1.000)', 'gorilla, Gorilla gorilla (prob: 0.000)', 'gibbon, Hylobates lar (prob: 0.000)', 'patas, hussar monkey, Erythrocebus patas (prob: 0.000)', 'howler monkey, howler (prob: 0.000)']\n",
            "['orangutan, orang, orangutang, Pongo pygmaeus (prob: 0.932)', 'gorilla, Gorilla gorilla (prob: 0.065)', 'guenon, guenon monkey (prob: 0.001)', 'siamang, Hylobates syndactylus, Symphalangus syndactylus (prob: 0.000)', 'gibbon, Hylobates lar (prob: 0.000)']\n",
            "['orangutan, orang, orangutang, Pongo pygmaeus (prob: 0.999)', 'howler monkey, howler (prob: 0.000)', 'siamang, Hylobates syndactylus, Symphalangus syndactylus (prob: 0.000)', 'gorilla, Gorilla gorilla (prob: 0.000)', 'spider monkey, Ateles geoffroyi (prob: 0.000)']\n",
            "['orangutan, orang, orangutang, Pongo pygmaeus (prob: 0.890)', 'spider monkey, Ateles geoffroyi (prob: 0.078)', 'howler monkey, howler (prob: 0.016)', 'gibbon, Hylobates lar (prob: 0.007)', 'siamang, Hylobates syndactylus, Symphalangus syndactylus (prob: 0.007)']\n",
            "['orangutan, orang, orangutang, Pongo pygmaeus (prob: 1.000)', 'siamang, Hylobates syndactylus, Symphalangus syndactylus (prob: 0.000)', 'gibbon, Hylobates lar (prob: 0.000)', 'titi, titi monkey (prob: 0.000)', 'guenon, guenon monkey (prob: 0.000)']\n",
            "['magpie (prob: 0.997)', 'black grouse (prob: 0.003)', 'water ouzel, dipper (prob: 0.000)', 'oystercatcher, oyster catcher (prob: 0.000)', 'bustard (prob: 0.000)']\n",
            "['ostrich, Struthio camelus (prob: 1.000)', 'black stork, Ciconia nigra (prob: 0.000)', 'bustard (prob: 0.000)', 'vulture (prob: 0.000)', 'bison (prob: 0.000)']\n",
            "['scorpion (prob: 0.987)', 'fiddler crab (prob: 0.009)', 'rock crab, Cancer irroratus (prob: 0.003)', 'crayfish, crawfish, crawdad, crawdaddy (prob: 0.000)', 'leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea (prob: 0.000)']\n",
            "['sea snake (prob: 1.000)', 'water snake (prob: 0.000)', 'king snake, kingsnake (prob: 0.000)', 'eel (prob: 0.000)', 'coral reef (prob: 0.000)']\n",
            "['tick (prob: 1.000)', 'weevil (prob: 0.000)', 'ground beetle, carabid beetle (prob: 0.000)', 'fly (prob: 0.000)', 'barn spider, Araneus cavaticus (prob: 0.000)']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}